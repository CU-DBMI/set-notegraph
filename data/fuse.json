{"keys":[{"path":["title"],"id":"title","weight":1,"src":"title","getFn":null},{"path":["body"],"id":"body","weight":1,"src":"body","getFn":null}],"records":[{"i":0,"$":{"0":{"v":"This page has not yet sprouted","n":0.408},"1":{"v":"[Dendron](https://dendron.so/) (the tool used to generate this site) lets authors selective publish content. You will see this page whenever you click on a link to an unpublished page\n\n![](https://foundation-prod-assetspublic53c57cce-8cpvgjldwysl.s3-us-west-2.amazonaws.com/assets/images/not-sprouted.png)","n":0.189}}},{"i":1,"$":{"0":{"v":"Home","n":1},"1":{"v":"## Welcome\n\nThis is the root page for the Software Engineering Team's (SET) notegraph. This content is organized using [Dendron](https://www.dendron.so/).\n\nNew team member onboarding should use the checklist: [[Software Engineering Team Onboarding Checklist|admin.onboading.checklist#software-engineering-team-onboarding-checklist]]","n":0.18}}},{"i":2,"$":{"0":{"v":"Training","n":1}}},{"i":3,"$":{"0":{"v":"Google","n":1}}},{"i":4,"$":{"0":{"v":"Digital Leader","n":0.707},"1":{"v":"\nGoogle Digital Leader Certification training information.\n\n## Details\n\n- Official page: <https://cloud.google.com/certification/cloud-digital-leader>\n- Exam Time Duration: 90 minutes\n- Exam Cost: $99\n- Exam Guide: <https://cloud.google.com/certification/guides/cloud-digital-leader>\n\n## Study Resources\n\n- __Google (Official)__\n  - Cloud Skills Boost: <https://cloud.google.com/training/business#cloud-digital-leader-path>\n  - Coursera: <https://www.coursera.org/professional-certificates/google-cloud-digital-leader-training>\n- __External (Unofficial)__\n  - <https://www.youtube.com/watch?v=UGRDM86MBIQ&ab_channel=freeCodeCamp.org>\n  - <https://youtube.com/watch?v=gddt4n_JEkk&t=4s>\n  - Visual Aids - <https://thecloudgirl.dev/sketchnote.html>\n","n":0.151}}},{"i":5,"$":{"0":{"v":"Resources","n":1}}},{"i":6,"$":{"0":{"v":"Personnel","n":1}}},{"i":7,"$":{"0":{"v":"Communities","n":1}}},{"i":8,"$":{"0":{"v":"West Big Data Innovation Hub","n":0.447},"1":{"v":"\nThis page outlines the [West Big Data Innovation Hub](https://www.westbigdatahub.org), part of the [NSF Big Data Hubs](https://bigdatahubs.org/) nationwide communities.\n\n> \"The West Big Data Innovation Hub is an inclusive community for catalyzing and scaling data science for societal needs. Our mission is to build and strengthen partnerships across academia, industry, nonprofits, and government—connecting research, education, and practice to harness the data revolution.\" ([https://www.westbigdatahub.org/about](https://www.westbigdatahub.org/about))\n","n":0.128}}},{"i":9,"$":{"0":{"v":"Research Network","n":0.707},"1":{"v":"\nThis page outlines personnel resources for research networking.\n\n## University of Colorado\n\n### Biomedical Focused (all CU campuses)\n\n- Colorado PROFILES: <https://profiles.ucdenver.edu/search/>\n\n### CU Boulder Focused\n\n- CU Experts: <https://experts.colorado.edu/>\n","n":0.2}}},{"i":10,"$":{"0":{"v":"Model","n":1}}},{"i":11,"$":{"0":{"v":"Data Mining","n":0.707}}},{"i":12,"$":{"0":{"v":"Knowledge Discovery in Databases","n":0.5},"1":{"v":"\n## Summary\n\n```mermaid\n    flowchart LR\n        data_input[(Data)]:::nohighlight --> selection[Select]:::nohighlight\n        selection --> preprocess[Prepocess]:::nohighlight\n        preprocess --> transform[Transform]:::nohighlight\n        transform --> mine[Data Mining]:::nohighlight\n        mine --> eval[Evaluate]:::nohighlight\n        \n        classDef nohighlight fill:#fff,stroke:#333\n```\n\n[Knowledge discovery in databases (KDD)](https://www.kdnuggets.com/gpspubs/aimag-kdd-overview-1996-Fayyad.pdf) is a [data mining](https://en.wikipedia.org/wiki/Data_mining) model with specific steps and interpretations. The above chart shows the general steps of this procedure.\n\n## References\n\n- From Data Mining to Knowledge Discovery in Databases - <https://www.kdnuggets.com/gpspubs/aimag-kdd-overview-1996-Fayyad.pdf>\n- Wikipedia Page on Data Mining - <https://en.wikipedia.org/wiki/Data_mining>\n- Related ACM Special Interest Group for KDD - <https://en.wikipedia.org/wiki/Special_Interest_Group_on_Knowledge_Discovery_and_Data_Mining>\n","n":0.115}}},{"i":13,"$":{"0":{"v":"Research Lifecycle","n":0.707},"1":{"v":"\n\n## Summary\n\n```mermaid\n    flowchart LR\n        subgraph Research Lifecycle\n            direction LR\n            Share:::nohighlight --> Discover\n            Discover:::nohighlight --> Plan\n            Plan:::nohighlight --> Acquire\n            Acquire:::nohighlight --> Process\n            Process:::nohighlight --> Analyze\n            Analyze:::nohighlight --> Preserve\n            Preserve:::nohighlight --> Share\n        end\n        \n        classDef nohighlight fill:#fff,stroke:#333\n```\n\n_Rough sketch of research lifecycle based on below references._\n\nThis page provides notes surrounding the \"Research Lifecycle\" as a heuristic model for working through research projects.\n\n> The Research Lifecycle is a heuristic model for understanding the steps of the process of scientific discovery (research), often represented in a wheel to emphasize the continuous nature of research with one project leading into the next.\n([https://nnlm.gov/guides/data-glossary/research-lifecycle](https://nnlm.gov/guides/data-glossary/research-lifecycle))\n\nIntepretations of the Research Lifecycle vary in their steps. Below are some references from various groups and institutions.\n\n## References\n\n- NNLM Research Lifecycle Definition - <https://nnlm.gov/guides/data-glossary/research-lifecycle>\n- The Research Lifecycle (CU Boulder) - <https://www.colorado.edu/crdds/what-we-do/research-lifecycle>\n- Research Lifecycle (The Open University) - <https://www.open.ac.uk/research/support/lifecycle>\n- Research Lifecycle (Amsterdam UMC) - <https://aph-qualityhandbook.org/research-lifecycle/>\n- Research Management Lifecycle (University of Washington) - <https://spaces.at.internet2.edu/download/attachments/30966076/Research%20Management%20LifeCycle%20%28from%20Jason%20Myers%202014-06-02%29.pdf?api=v2>\n\n## Related\n\n- Kaizen, continuous improvement - <https://en.wikipedia.org/wiki/Kaizen>\n  - While different in focus, kaizen procedures have many similarities which may be beneficial to consider in context with the research lifecycle, such as PDCA loops, etc.\n","n":0.074}}},{"i":14,"$":{"0":{"v":"Funding","n":1}}},{"i":15,"$":{"0":{"v":"Grants Management","n":0.707},"1":{"v":"\n## Summary\n\nIn the early and/or planning phase of the research lifecycle one may seek funding opportunities in the form of grants. Grant management is an area of focus which has specific procedures and solutions. See the additional definition below for more information.\n\n> \"Grant management solutions are leveraged by federal, state and local governments, as well as higher education, research, and biomedical institutions and nonprofit organizations to meet their fiduciary responsibilities in demonstrating transparency and accountability in managing the performance of grants.\" - [https://www.gartner.com/en/information-technology/glossary/grant-management-solutions](https://www.gartner.com/en/information-technology/glossary/grant-management-solutions)\n\n## Software / Solutions\n\nListing in no particular order software solutions which exist to address grants management.\n\n- __Open Source__:\n  - [Gandhi](https://github.com/mike-marcacci/gandhi)\n- __Proprietary/SaaS__:\n  - [InfoEd Grant Management](https://www.infoedglobal.com/products/grants-and-contracts/)\n    - University of Colorado informational link: [Electronic Research Administration (eRA)](https://www.cu.edu/uis/electronic-research-and-administration-era)\n    - [Crunchbase](https://www.crunchbase.com/organization/infoed-global)\n    - [Overview](https://www.youtube.com/watch?v=F5vGjnn69_8&ab_channel=InfoEdGlobal)\n  - [Fluxx Grantseeker](https://grantseeker.fluxx.io/)\n    - [Crunchbase](https://www.crunchbase.com/organization/fluxx)\n    - [Overview](https://www.youtube.com/watch?v=qwUFiHmfQsA&ab_channel=Fluxx)\n  - [GrantHub](https://grantseekers.foundant.com/product/)\n    - [Crunchbase](https://www.crunchbase.com/organization/granthub)\n    - [Overview](https://www.youtube.com/watch?v=41deec_hANg&ab_channel=MontanaNonprofitAssociation)\n  - [Submittable](https://www.submittable.com/grants-management)\n    - [Crunchbase](https://www.crunchbase.com/organization/submishmash)\n    - [Overview](https://www.youtube.com/watch?v=YzCCpl1FTyQ&ab_channel=Submittable)\n  - [Zengine by WizeHive](https://www.wizehive.com/)\n    - [Crunchbase](https://www.crunchbase.com/organization/wizehive)\n    - [Overview](https://www.youtube.com/watch?v=eO5g66-24JM&ab_channel=wizehive)\n  - [Blackbaud Grantmaking](https://www.blackbaud.com/solutions/grant-and-award-management/grantmaking)\n    - Part of larger brand, [Blackbaud](https://en.wikipedia.org/wiki/Blackbaud)\n    - [Crunchbase](https://www.crunchbase.com/organization/blackbaud)\n    - [Overview](https://www.youtube.com/watch?v=PH2dD0TWkY4&ab_channel=Blackbaud)\n  - [Grant Administrator by Dyna-Quest](http://www.dyna-quest.com/GA/gadescription.htm)\n    - [Crunchbase](https://www.crunchbase.com/organization/dyna-quest-technologies)\n\n## References\n\n- Gartner Grants Management Definition: <https://www.gartner.com/en/information-technology/glossary/grant-management-solutions>\n- Capterra listing of Grant Management Software ratings: <https://www.capterra.com/grant-management-software/>\n- Introduction to Grants Management from University of South Carolina <https://www.youtube.com/watch?v=8_Jxy4KfHdA&ab_channel=USCPeopleSoftTraining>\n","n":0.072}}},{"i":16,"$":{"0":{"v":"Methodology","n":1}}},{"i":17,"$":{"0":{"v":"Translational Science","n":0.707},"1":{"v":"\n## Summary\n\nThis page provides notes surrounding \"Translational Science\" as a methodology for performing scientific research.\n\nSee below for some definitions of Translational Science.\n\n>\"Translational research (also called translation research, translational science, or, when the context is clear, simply translation) is research aimed at translating (converting) results in basic research into results that directly benefit humans.\" (_[https://en.wikipedia.org/wiki/Translational_research](https://en.wikipedia.org/wiki/Translational_research)_)\n\n- Wikipedia page on Translational Research: <https://en.wikipedia.org/wiki/Translational_research>\n- Colorado Clinical and Translational Sciences Institute: <https://cctsi.cuanschutz.edu/>\n- US Dept. of Health & Human Services - National Center for Advancing Translational Sciences - <https://ncats.nih.gov/index.php>\n","n":0.11}}},{"i":18,"$":{"0":{"v":"Team Science","n":0.707},"1":{"v":"\n## Summary\n\nThis page provides notes surrounding \"Team Science\" as a methodology for performing scientific research.\n\nSee below for some definitions of Team Science.\n\n>Team science is a collaborative effort to address a scientific challenge that leverages the strengths and expertise of professionals, oftentimes trained in different fields. ([_https://cancercontrol.cancer.gov/brp/research/team-science-toolkit/what-is-team-science_](https://cancercontrol.cancer.gov/brp/research/team-science-toolkit/what-is-team-science))\n\n>Team science initiatives are designed to promote collaborative, and often cross-disciplinary (which includes multi-, inter-, and transdisciplinary) approaches to answering research questions about particular phenomena. ([_https://en.wikipedia.org/wiki/Science_of_team_science_](https://en.wikipedia.org/wiki/Science_of_team_science))\n\n## Science of Team Science (SciTS)\n\nIt's important to note that the Science of Team Science is treated as a separate area of study:\n\n>The SciTS field, on the other hand, is concerned with understanding and managing circumstances that facilitate or hinder the effectiveness of collaborative science, and evaluating the outcomes of collaborative science.([_https://en.wikipedia.org/wiki/Science_of_team_science_](https://en.wikipedia.org/wiki/Science_of_team_science))\n\n## Resources\n\n### Team Science\n\n- TeamScience.net: resources covering various Team Science aspects (<https://www.teamscience.net/home>)\n- NIH NCI Division of Cancer Control & Population Sciences - Behavioral Research Program - Team Science Toolkit (<https://cancercontrol.cancer.gov/brp/research/team-science-toolkit>)\n- CU Boulder Research & Innovation Office - Team Science - <https://www.colorado.edu/researchinnovation/team-science>\n\n### Science of Team Science\n\n- International Network for the Science of Team Science (INSciTS) (<https://www.inscits.org/about-us>)\n- Wikipedia Page (<https://en.wikipedia.org/wiki/Science_of_team_science>)\n","n":0.075}}},{"i":19,"$":{"0":{"v":"Data","n":1}}},{"i":20,"$":{"0":{"v":"Secure Data Transfer","n":0.577},"1":{"v":"\n## Summary\n\nCovering secure data transfer tools for use within CU Anschutz.\n\nNote: this page is for reference only and should not be considered direction or permission to upload sensitive data to these resources.\n\n- __Egnyte__: for pay software licensed solution which may be used to transfer data. See <https://som.cuanschutz.edu/ResearchResources/> and select \"Egnyte\" for more details near the bottom of the page.\n- __CU Transfer__: SFTP service hosted by CU System which can provide file transfers to various resources. See <https://www.cu.edu/uis/cu-transfer-access> for more details.\n- __Microsoft OneDrive__: cloud-based service which ties into Microsoft account through the University. See: <https://en.wikipedia.org/wiki/OneDrive> for more information.\n","n":0.102}}},{"i":21,"$":{"0":{"v":"Health Data Compass","n":0.577},"1":{"v":"\n## Summary\n\nHealth Data Compass is a joint initiative of the University of Colorado Anschutz Medical Campus, CU Medicine, UCHealth, and Children's Hospital Colorado. Health Data Compass provides health data access through a unified portal.\n\nMore information may be found here: <https://www.healthdatacompass.org/home>\n\n## Access\n\nPlease see the access request form on the above link page for more information.\n\n## Training\n\nAn orientation on Health Data Compass offerings may be found here: <https://www.healthdatacompass.org/data-delivery-services/compass-orientation>\n","n":0.123}}},{"i":22,"$":{"0":{"v":"Central Information Warehouse","n":0.577},"1":{"v":"\n## Summary\n\nCIW is a data warehouse run by a team within UIS called \"IRM\" (also known as Data and Business Intelligence). CIW contains various data associated with source systems.\n\n> \"The Central Information Warehouse (CIW) provides the source data used in Cognos reports (CU-Data) and Tableau data visualizations.\"\n\n> \"The CIW and CU-Data Reporting System is CU's system-wide centralized data repository for information sourced from administrative systems, included are the Human Capital Management (HCM), Finance, Student Integrated System (CU-SIS), eRA, Advancement and more.\"\n\n[https://content.cu.edu/irm/](https://content.cu.edu/irm/)\n\n## Data Model\n\nCIW's Data Model is based of [PeopleSoft's EPM](https://docs.oracle.com/cd/E29700_01/epm91fp1/eng/psbooks/pcsw/chapter.htm?File=pcsw/htm/pcsw04.htm) with multiple notable additions, that were created in house, the majority of which include CU_ in their names.\n\n## Access\n\n### Notes\n\nAccess to various source data is controlled by way of user accounts and related schema. Within certain schema one may have limited access to data based on requests and approvals. It's important to note that some organizations and teams have different access than others.\n\n### Access Requests\n\nAccess requests can be found on the following page: [https://www.cu.edu/uis/central-information-warehouse-ciw-access](https://www.cu.edu/uis/central-information-warehouse-ciw-access)\n\n## Schedule and Status\n\nSource data schedule and status information can be found on the following page: [https://content.cu.edu/irm/CUonly/dwhse/status/ciw_status.cgi](https://content.cu.edu/irm/CUonly/dwhse/status/ciw_status.cgi)\n\nPlease note that individual data sources have data availability SLA's which may effect access to related datasets. See below data source pages for more details.\n\n## CIW Data Sources\n\n- __CU-SIS__: <https://content.cu.edu/irm/CUonly/dwhse/cusis/cusis.html>\n- __eRA__: <https://content.cu.edu/irm/CUonly/dwhse/eRA/>\n- __Finance__: <https://content.cu.edu/irm/CUonly/dwhse/Finance/Index.html>\n- __HCM__: <https://content.cu.edu/irm/CUonly/dwhse/hcm/index.html>\n- __PSC__: <https://content.cu.edu/irm/CUonly/dwhse/PSC/index.html>\n- __Advancement__: <https://content.cu.edu/irm/CUonly/dwhse/Advancement/index.html>\n","n":0.068}}},{"i":23,"$":{"0":{"v":"Administrative Analysis Environment","n":0.577},"1":{"v":"\n## Summary\n\nThe Administrative Analysis Environment (A2E) provides University of Colorado Anschutz (CU Anschutz) School of Medicine (SoM) data resources as a unified data warehouse. The focus is generally on administrative-use data.\n\n## Access\n\nSee the following webiste for more information: <https://som.ucdenver.edu/A2E/>\n\n## Training\n\nA training course covering the use of A2E may be found within the University's Skillsoft instance: \"CU: Administrative Analysis Environment (A2E) Basics\"(_scorm12_cu_u00202_0001)\n","n":0.128}}},{"i":24,"$":{"0":{"v":"Compute","n":1}}},{"i":25,"$":{"0":{"v":"CU Boulder Summit","n":0.577},"1":{"v":"\n## Summary\n\nResearch Computing (RC) through the University of Colorado Boulder (CU Boulder) provides a supercomputer resource called __Summit__. For more information see the following webpage: <https://colorado.edu/rc/resources/summit>.\n\n## CU Anschutz Access\n\n|__:warning: PLEASE NOTE__|\n|:---------------------------|\n| :exclamation: XSEDE SSO access will be discontinued as of 8/31/2022 ([see here](https://portal.xsede.org/web/advancetoaccess/-/important-information-for-access-resource-providers?redirect=https%3A%2F%2Fportal.xsede.org%2Fweb%2Fadvancetoaccess%2Fhome%3Fp_p_id%3D101_INSTANCE_GGZQtbM1Lixt%26p_p_lifecycle%3D0%26p_p_state%3Dnormal%26p_p_mode%3Dview%26p_p_col_id%3D_118_INSTANCE_PAjp68kDKWMl__column-1%26p_p_col_count%3D1)). Moving forward, RMACC users (CU Anschutz included) may use ACCESS and Open OnDemand to access Summit and other RC items. |\n\nThose with University of Colorado Anschutz (CU Anschutz) may access the Summit supercomputing resource using an [ACCESS account](https://access-ci.org/) and Open OnDemand.\n\nUse the following guide for more information:\n<https://curc.readthedocs.io/en/latest/access/rmacc.html>\n\nSlides covering Open OnDemand specifically: <https://github.com/ResearchComputing/OpenOnDemand>\n\nUser Q&A Portal: <https://ask.cyberinfrastructure.org/c/rmacc/65>\n","n":0.101}}},{"i":26,"$":{"0":{"v":"Tools","n":1}}},{"i":27,"$":{"0":{"v":"Testing","n":1}}},{"i":28,"$":{"0":{"v":"Python","n":1},"1":{"v":"\nCovering some testing tools for Python.\n\n## Testing frameworks or enablers\n\n- [pytest](https://docs.pytest.org/)\n- [unittest](https://docs.python.org/3/library/unittest.html)\n- [nose](https://nose.readthedocs.io/en/latest/index.html)\n- [tox](https://tox.wiki/en/latest/)\n\n## Testing specifics\n\n- [coverage.py](https://github.com/nedbat/coveragepy) Test case code coverage.\n- [mutmut](https://github.com/boxed/mutmut) Mutation testing\n- [hypothesis](https://hypothesis.works/) Property based testing (generating data for tests)\n","n":0.177}}},{"i":29,"$":{"0":{"v":"Project Management","n":0.707}}},{"i":30,"$":{"0":{"v":"GitHub Projects","n":0.707},"1":{"v":"\nNotes about using [Github Projects](https://docs.github.com/en/issues/planning-and-tracking-with-projects/learning-about-projects/about-projects) for work visibility and planning.\n\nGithub Projects allows you to collect, organize and visualize existing or upcoming repository issues in one spot. Project spaces may be created at the repo, user, or organization level.\n\nGithub Projects is segmented by two historical versions: \"legacy\" and \"current/existing\". Legacy acts slightly different than the current/existing version.\n\n## Cross-Organizational Use for External Issues\n\nMuch of Github Projects is aimed at a single repository or organization's issues but there are ways to integrate external issues into projects.\n\nOne way to do this is by using the Github Issue URL and pasting this into the Github Project directly as a new issue row, which can be automatically ingested as an existing issue within the board. Note: For issues imported in this way, the Project may not appear alongside the issue from it's display in the external organization.\n","n":0.084}}},{"i":31,"$":{"0":{"v":"Linting","n":1}}},{"i":32,"$":{"0":{"v":"Python","n":1},"1":{"v":"\nCovering some linting tools for Python.\n\n## General Code Style (and usually more!)\n\n- [pylint](https://pylint.pycqa.org/en/latest/)\n- [flake8](https://flake8.pycqa.org/en/latest/)\n\n## Security\n\n- [bandit](https://bandit.readthedocs.io/en/latest/)\n- [safety](https://pyup.io/safety/)\n\n## Typing\n\n- [mypy](http://mypy-lang.org/)\n\n## Formatting Specific\n\n- [black](https://black.readthedocs.io/en/stable/)\n- [isort](https://pycqa.github.io/isort/)\n- [vulture](https://github.com/jendrikseipp/vulture)\n- [pycodestyle](https://github.com/PyCQA/pycodestyle)\n\n## Documentation (Python-specific)\n\n- [pyment](https://github.com/dadadel/pyment)\n- [blacken-docs](https://github.com/asottile/blacken-docs)\n","n":0.186}}},{"i":33,"$":{"0":{"v":"Documentation","n":1},"1":{"v":"\nCovering some linting tools for documentation.\n\n## General\n\n- [doc8](https://github.com/PyCQA/doc8): rst linter\n- [markdownlint](https://github.com/DavidAnson/markdownlint): markdown linting\n- [textlint](https://textlint.github.io/): Natural language linter\n","n":0.243}}},{"i":34,"$":{"0":{"v":"Data","n":1}}},{"i":35,"$":{"0":{"v":"Validation","n":1},"1":{"v":"\nTools for data validation.\n\n## Schema-based Validation\n\nUsing static schema definitions to validate data.\n\n### Apache-project Based\n\n- [Avro (pythonic implementation)](https://avro.apache.org/docs/1.11.1/getting-started-python/): Python library for using [Apache Avro](https://avro.apache.org/docs/).\n- [Apache Arrow Table Schema Validate (PyArrow)](https://arrow.apache.org/docs/python/generated/pyarrow.Table.html#pyarrow.Table.validate): Validates [Apache Arrow](https://arrow.apache.org/docs/index.html) schema.\n- [Apache Parquet Schema (PyArrow)](https://arrow.apache.org/docs/python/generated/pyarrow.parquet.ParquetFile.html#pyarrow.parquet.ParquetFile.schema): Gathers but no embedded validate functionality for Parquet-based schema. Note: may use Arrow-based schema validation through PyArrow.\n\n### JSON-based\n\n- [jsonschema (pythonic implementation)](https://python-jsonschema.readthedocs.io/en/stable/): Python library for using [JSON Schema](https://json-schema.org/) functionality.\n\n### Independent\n\n- [Cerberus](https://github.com/pyeve/cerberus): custom data validation system for python.\n- [Deequ](https://github.com/awslabs/deequ): schema and profile based data unit-testing framework based on [Apache Spark](https://spark.apache.org/).\n- [Pydantic](https://pydantic-docs.helpmanual.io/): Pythonic data validation library.\n- [Marshmallow](https://marshmallow.readthedocs.io/en/stable/): Pythonic data ORM/ODM and validation library.\n- [Pandas `assert_frame_equal`](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.testing.assert_frame_equal.html): validate Pandas dataframes against one another.\n- [Pandera](https://pandera.readthedocs.io/en/latest/index.html): Pythonic dataframe-focused schema validation.\n- [Voluptuous](https://github.com/alecthomas/voluptuous): custom data validation system for python.\n- [Schema (Python)](https://github.com/keleshev/schema): Pythonic schema validation.\n\n### Language\n\n- [Cuelang](https://cuelang.org/): data, schema, and validation language, all-in-one.\n\n## Profile-based Validation\n\nUsing profiles of data (as opposed to static schema definition) to validate data.\n\n- [Great Expectations](https://docs.greatexpectations.io/docs/): implements profile-based data quality checks and validation for your data.\n- [Soda](https://docs.soda.io/soda/quick-start-soda-core.html): implements profile-based data quality checks and validation for your data.\n- [DeepChecks](https://docs.deepchecks.com/stable/getting-started/welcome.html): intended from ML data profile validation.\n","n":0.076}}},{"i":36,"$":{"0":{"v":"Build","n":1}}},{"i":37,"$":{"0":{"v":"Python","n":1}}},{"i":38,"$":{"0":{"v":"Environment","n":1},"1":{"v":"\nBuild tools for Python Environments. In order to ensure reproducibility, a Python developer might make use of specific build tools for their environment. These tools generally try to make sure Python binaries, packages, versions, and cross-dependencies are maintained and source controlled where possible. They also greatly enhance specifications sometimes found within `requirements.txt` files. For more information, see: [Why requirements.txt isn't enough](https://modelpredict.com/wht-requirements-txt-is-not-enough).\n\nBelow is a list of just a few of these tools. Please note: there is not always feature parity between these, it's recommended to only use at your own discretion after investigation.\n\n- [Poetry](https://python-poetry.org/)\n- [PDM](https://pdm.fming.dev/latest/)\n- [Pipenv](https://pipenv.pypa.io/en/latest/)\n- [Conda](https://docs.conda.io/en/latest/)\n- [Pyenv](https://github.com/pyenv/pyenv)\n","n":0.102}}},{"i":39,"$":{"0":{"v":"Dagger","n":1}}},{"i":40,"$":{"0":{"v":"Project Init","n":0.707},"1":{"v":"\n## Summary\n\nProjects which use [Dagger](https://docs.dagger.io/) must be initialized to include dependencies from the core library in order to run. While it's recommended to include these dependencies as part of the project ([reference](https://docs.dagger.io/1225/pushing-plan-dependencies/)), there are sometimes many additional files included as part of this (any possible dependency is included, instead of those referenced only). See the below for getting started with a dagger project.\n\n## Steps\n\n1. Create a `<name>.cue` file to include your custom Dagger work.\n1. Use command `dagger project init` from within the same dir as the cue file.\n1. There are sometimes issues with project init, and you may also need to use `dagger project update` immediately after initializing your project.\n1. Use command `dagger do <action name>` as needed.\n","n":0.092}}},{"i":41,"$":{"0":{"v":"Presentation 2022 07 07","n":0.5},"1":{"v":"\n<!-- slide -->\n\n# Dagger\n\n### <span style=\"color:#aaa; text-align:center;\">Portable Development <br> with Cuelang</span>\n\n<!-- slide -->\n\n## Intro\n\n<br>\n\n[Dagger](https://github.com/dagger/dagger) is a portable development tool implemented through [Cuelang](https://github.com/cue-lang/cue).\n<br>\n\n```mermaid\ngraph LR\n  cue[ *.cue File ] --> dagger[ cmd: dagger do 'action' ]\n  dagger --> buildkit\n  buildkit --> do[perform 'action']\n```\n\n<!-- slide -->\n\n## What's Cuelang?\n\n> <span style=\"text-align:left;float:left;\"> CUE is an open-source data validation language and inference engine with ... many applications, such as data __validation__, data __templating__, __configuration__, __querying__, __code generation__ and even __scripting__.\"</span>\n\n[https://cuelang.org/docs/about/](https://cuelang.org/docs/about/)\n\n<!-- slide -->\n\n## What's Cuelang?\n\nData values and schema together 😮\n<table>\n<tr>\n<td>\n\n```json\n// JSON\n// values\n{ \n  \"denver\": {\n    \"name\": \"Denver\",\n    \"state\": \"CO\",\n    \"pop\": 760049,\n    \"capital\": true\n  }\n}\n```\n\n</td>\n<td>\n\n```json\n// CUE\n// values, schema, and more\nbigCity: {\n    // type\n    name: string\n    // default value\n    state: string | *\"CO\"\n    // operators, shorthand\n    pop: >700K\n    // value\n    capital: true\n}\n```\n\n</td>\n</tr>\n</table>\n\n<!-- slide -->\n\n### Cuelang probably deserves <br> it's own conversation! 🙂\n\n<!-- slide -->\n\n## What's Dagger?\n\n<br>\n\n1. Build a .cue file\n1. Use dagger client to implement (wherever)\n1. Dagger uses [buildkit](https://github.com/moby/buildkit) to perform action\n<br>\n\n```mermaid\ngraph LR\n  cue[ *.cue File ] --> dagger[ cmd: dagger do 'stuff' ]\n  dagger --> buildkit\n  buildkit --> do[perform 'stuff']\n```\n\n<!-- slide -->\n\n## Example Usecase\n\n1. Build a repo .cue file for testing\n1. __Test locally__ with dagger client\n1. __Test remotely__ with [Github Action](https://github.com/dagger/dagger-for-github) (running the same file)\n1. __Celebrate__ 🥳 <br>(because there weren't surprises with local vs remote testing!)\n\n<!-- slide -->\n\n## Installation: __Dagger Cli__\n\n- macOS: `brew` or `curl + shell`\n- Windows: `psl`, `choco`, or `scoop`\n- Linux: `curl + shell`\n\n<https://docs.dagger.io/install>\n\n<!-- slide -->\n\n## Installation: __Buildkit__\n\nDagger needs a place to invoke buildkit.\n\n- __Docker Desktop__ (built-in compatibility)\n- __Podman__ (some pre-config)\n- __Kubernetes__ (some pre-config)\n- __Remotes__ (BYO remote environment)\n\n<https://docs.dagger.io/1223/custom-buildkit/>\n\n<!-- slide -->\n\n## Demo\n\n[Link here]()\n","n":0.063}}},{"i":42,"$":{"0":{"v":"Buildkit and Podman","n":0.577},"1":{"v":"\n## Summary\n\n[Dagger](https://docs.dagger.io/) by default will attempt to use Docker installations but does not require Docker to run. Some customization without using Docker is covered on the following page: [Customizing your Buildkit installation](https://docs.dagger.io/1223/custom-buildkit/). The following covers how to use Dagger with containerized Buildkit using Podman.\n\n## Steps\n\n1. [Install Podman](https://podman.io/getting-started/installation)\n1. Run Buildkit using the following, modifying as appropriate for your system: `podman run -d --name buildkitd --privileged -p 1234:1234 moby/buildkit:latest --addr tcp://0.0.0.0:1234` ([reference](https://github.com/moby/buildkit#podman) and [issue for podman explicit ports](https://github.com/dagger/dagger/issues/1959#issuecomment-1101547522))\n1. [Install Dagger](https://docs.dagger.io/1200/local-dev)\n1. Set BUILDKIT_HOST environment variable to podman-container://buildkit , for ex: `export BUILDKIT_HOST=tcp://localhost:1234` ([reference](https://docs.dagger.io/1223/custom-buildkit/) and [issue for podman explicit ports](https://github.com/dagger/dagger/issues/1959#issuecomment-1101547522))\n1. Run Dagger commands as necessary.\n","n":0.1}}},{"i":43,"$":{"0":{"v":"Workflow","n":1},"1":{"v":"\nThe usual suspects. Here's a good overview, <https://ploomber.io/blog/survey/>. The ploober document lists the following, but it's also a sales site, so listing tools separately without opinion:\n\n- [Ploomber](https://ploomber.io)\n- [Airflow](https://airflow.apache.org)\n- [Dagster](https://www.dagster.io)\n- DVC (Data Pipelines)\n- Elyra\n- Flyte\n- Kale\n- Kedro\n- Kubeflow pipelines\n- Luigi\n- Metaflow\n- [Prefect](https://www.prefect.io)\n- Tensorflow Extended (TFX)\n\n[DBT](https://www.getdbt.com) is an \"data transformation tool,\" more focused on flowing SQL and database data, but very powerful there.\n\n[Nextflow](https://www.nextflow.io/), a Java tool, is especially liked in the academic research community.\n\nUseful in the academic and research environment, we've run across [SnakeMake](https://snakemake.readthedocs.io/en/stable/index.html).\n\n[Ray Workflows](https://docs.ray.io/en/latest/workflows/basics.html) - Part of the Ray distributed compute project.\n\n[Globus Flows](https://www.globus.org/platform/services/flows) - Part of Globus, a research-focused data management suite.\n","n":0.1}}},{"i":44,"$":{"0":{"v":"Measurement","n":1},"1":{"v":"\nNotes concerning tools for measurement.\n\n## Measures\n\n- [Key Performance Indicators (KPI)](https://en.wikipedia.org/wiki/Performance_indicator)\n  > \"KPIs evaluate the success of an organization or of a particular activity (such as projects, programs, products and other initiatives) in which it engages.\" ([Wikipedia](https://en.wikipedia.org/wiki/Performance_indicator))\n\n## Performance\n\n- [360-degree Feedback](https://en.wikipedia.org/wiki/360-degree_feedback)\n  > \"A 360-degree feedback (also known as multi-rater feedback, multi source feedback, or multi source assessment) is a process through which feedback from an employees subordinates, colleagues, and supervisor(s), as well as a self-evaluation by the employee themselves is gathered.\"([Wikipedia](https://en.wikipedia.org/wiki/360-degree_feedback))\n- [Objective Key Results (OKR)](https://en.wikipedia.org/wiki/OKR)\n  > \"Objectives and key results (OKR, alternatively OKRs) is a goal-setting framework used by individuals, teams, and organizations to define measurable goals and track their outcomes.\"([Wikipedia](https://en.wikipedia.org/wiki/OKR))\n","n":0.096}}},{"i":45,"$":{"0":{"v":"Leaning Management","n":0.707},"1":{"v":"\nListing of learning management tools.\n\n- [UC Denver / Anschutz Canvas](https://www.ucdenver.edu/offices/office-of-information-technology/software/how-do-i-use/canvas)\n  - [Canvas Co-Curricular Course Request (non-credit)](https://ucdenverdata.formstack.com/forms/cocurricularrequest)\n- [Github Classroom](https://docs.github.com/en/education/manage-coursework-with-github-classroom/teach-with-github-classroom)\n  - [Getting Started Guide](https://www.youtube.com/playlist?list=PLIRjfNq867bewk3ZGV6Z7a16YDNRCpK3u)\n","n":0.213}}},{"i":46,"$":{"0":{"v":"K8s","n":1}}},{"i":47,"$":{"0":{"v":"Knative","n":1}}},{"i":48,"$":{"0":{"v":"Install","n":1},"1":{"v":"\n## Prerequisites and Tools\n\nAssumes kubectl is already installed on your workstation.\n\nLens is recommended for watching deployment, service and pod provisioning. https://k8slens.dev/\n\nReview the knative install guide: https://knative.dev/docs/install/operator/knative-with-operators/#install-the-knative-operator\n\nRequires `helm`.\n\nYAML files referenced in this doc are under \\src\\knative-install-resources.\n\nThis doc is written against knative 1.3.1.\n\n## Install Kubernetes Control Plane and Workers\n\nInstall a zone cluster (1 per billing account is free) for MVP.\n\nThis is currently installed as one large cluster, but instead install the cluster, create an autoscaling worker pool, then delete the default pool. \n\nTODO - refactor for the above and include reference to the terraform.\n\n```\ngcloud container --project \"cuhealthai-foundations\" clusters create \"zonal-cluster-1\" --zone \"us-central1-c\" --no-enable-basic-auth --cluster-version \"1.21.6-gke.1500\" --release-channel \"regular\" --machine-type \"e2-medium\" --image-type \"COS_CONTAINERD\" --disk-type \"pd-standard\" --disk-size \"100\" --metadata disable-legacy-endpoints=true --scopes \"https://www.googleapis.com/auth/devstorage.read_only\",\"https://www.googleapis.com/auth/logging.write\",\"https://www.googleapis.com/auth/monitoring\",\"https://www.googleapis.com/auth/servicecontrol\",\"https://www.googleapis.com/auth/service.management.readonly\",\"https://www.googleapis.com/auth/trace.append\" --max-pods-per-node \"110\" --num-nodes \"3\" --logging=SYSTEM,WORKLOAD --monitoring=SYSTEM --enable-ip-alias --network \"projects/cuhealthai-foundations/global/networks/default\" --subnetwork \"projects/cuhealthai-foundations/regions/us-central1/subnetworks/default\" --no-enable-intra-node-visibility --default-max-pods-per-node \"110\" --no-enable-master-authorized-networks --addons HorizontalPodAutoscaling,HttpLoadBalancing,GcePersistentDiskCsiDriver --enable-autoupgrade --enable-autorepair --max-surge-upgrade 1 --max-unavailable-upgrade 0 --enable-shielded-nodes --node-locations \"us-central1-c\"\n```\n\nConfigure .kube/config with credentials for the new cluster.\n\n    gcloud container clusters get-credentials zonal-cluster-1 --zone us-central1-c --project cuhealthai-foundations\n\nCopy the cluster config secret(s) to the password vault.\n\nOnce the cluster is up, fetching nodes should show something like this (example):\n\n```\n$>kubectl get nodes\nNAME                                             STATUS   ROLES    AGE     VERSION\ngke-zonal-cluster-1-default-pool-1915e7e8-2wz5   Ready    <none>   6m43s   v1.21.6-gke.1500\ngke-zonal-cluster-1-default-pool-1915e7e8-dlht   Ready    <none>   6m43s   v1.21.6-gke.1500\ngke-zonal-cluster-1-default-pool-1915e7e8-qcq1   Ready    <none>   6m43s   v1.21.6-gke.1500\n```\n\n## Install knative\n\nInstall the knative operator:\n\n    kubectl apply -f https://github.com/knative/operator/releases/download/knative-v1.3.1/operator.yaml\n\nVerify the installation; the deployment should be available (example):\n\n```\n$>kubectl get deployment knative-operator\nNAME               READY   UP-TO-DATE   AVAILABLE   AGE\nknative-operator   1/1     1            1           69s\n```\n\n### knative-serving\n\nInstall the knative-serving file:\n\n    kubectl apply -f knative-serving.yaml\n\nFetch the external IP address for DNS configuration:\n\n    kubectl --namespace knative-serving get service kourier\n\nIt may take a minute, but eventually the EXTERNAL-IP address will be assigned (example shown).\n\n```\nNAME      TYPE           CLUSTER-IP    EXTERNAL-IP     PORT(S)                      AGE\nkourier   LoadBalancer   10.0.10.151   34.123.218.33   80:31370/TCP,443:31963/TCP   38s\n```\n\nVerify knative-serving is running:\n\n    kubectl get KnativeServing knative-serving -n knative-serving\n\nYou should see READY = True.\n\n```\nNAME              VERSION   READY   REASON\nknative-serving   1.3.0     True\n```\n\nGiven the EXTERNAL-IP from a couple steps above, configure DNS `*.default` and `*.center` to a A records. `default` and `center` map here to k8s namespaces. For every new namespace used with knative, we need to add a separate wildcard A entry.\n\n### knative-eventing\n\nInstall knative-eventing:\n\n    kubectl apply -f knative-eventing.yaml\n\nThere are lots of eventing sources. TBD how we'll use these.\n\n## Configure TLS\n\nFollowing this guide, and assuming the use of the HTTP-01 challenge. https://knative.dev/docs/serving/using-auto-tls/#enabling-auto-tls\n\nAdd the cert-manager controller.\n\n    kubectl apply --filename https://github.com/knative/net-certmanager/releases/download/knative-v1.3.0/release.yaml\n\nInstall cert-manager.\n\n    helm repo add jetstack https://charts.jetstack.io\n    helm repo update\n    helm install cert-manager jetstack/cert-manager --namespace cert-manager --create-namespace --version v1.7.1 --set installCRDs=true\n\nInstall cluster issuer:\n\n    kubectl apply -f letsencrypt-http01-issuer.yaml\n\nCheck to cluster issuer to see that READY = True:\n\n    kubectl get clusterissuer letsencrypt-http01-issuer\n\nAdd a configmap for the certmananger:\n\n    kubectl apply -f config-certmanager.yaml\n\nEnable Auto-TLS. I'm patching below, but with Windows you may have to manually edit.\n\n    kubectl patch configmap config-network --namespace knative-serving -p '{\"data\":{\"auto-tls\":\"Enabled\",\"autocreate-cluster-domain-claims\":\"true\"}}'\n\nInstall a garbage collection policy\n\n    kubectl apply -f gc.yaml\n","n":0.048}}},{"i":49,"$":{"0":{"v":"Documentation","n":1},"1":{"v":"\nDocumentation tooling.\n\n## Languages\n\nLanguages for building documentation\n\n- [reStructuredText(RST)](https://docutils.sourceforge.io/rst.html)\n- [Markdown](https://daringfireball.net/projects/markdown/)\n- [[Link: Diagramming Languages | tools.diagrams#code-based]]\n\n## API-focused Static Site Generators\n\nGenerate human-readable content from API's and your code.\n\n- [Sphinx](https://www.sphinx-doc.org/en/master/)\n- [MkDocs](https://www.mkdocs.org/)\n- [mkdocstrings](https://mkdocstrings.github.io/)\n- [Docsify](https://docsify.js.org/)\n- [Slate](https://github.com/slatedocs/slate)\n- [Docusaurus](https://github.com/facebook/docusaurus)\n\n## Wiki-focused Static Site Generators\n\nGenerate human-readable content using wiki-style format for knowledge collections.\n\n- [Dendron](https://wiki.dendron.so/)\n\n## Hosting\n\nHosting for static site generated content.\n\n- [ReadTheDocs](https://readthedocs.org/)\n- [Github Pages](https://pages.github.com/)\n","n":0.139}}},{"i":50,"$":{"0":{"v":"Dendron","n":1}}},{"i":51,"$":{"0":{"v":"Create Note from Jupyter Notebook","n":0.447},"1":{"v":"\n## Summary\n\nThe following note covers how to create Dendron-compatible notes from Jupyter notebook files.\n\n- Jupyter notebooks are JSON files used to compose markdown and code intended to be executed within specialized notebook-compatible environments.\n- Dendron notes are markdown files with frontmatter.\n- Jupytext may be used to create Markdown files from Jupyter notebooks.\n\n## Process\n\n1. Begin with a Jupyter notebook file\n1. Install [Jupytext](https://jupytext.readthedocs.io/en/latest/)\n1. [Pair Jupyter notebook file with markdown file](https://jupytext.readthedocs.io/en/latest/paired-notebooks.html)\n1. Apply [Dendron Doctor: fixFrontMatter](https://wiki.dendron.so/notes/ZeC74FYVECsf9bpyngVMU/#fixfrontmatter) to resulting markdown file.\n1. Enjoy the Jupyter notebook as a Dendron note ✅\n\nSpecial notes:\n\n- Output from Jupyter notebook cells are not saved by Jupytext when converting to markdown.\n- Each time the notebook is saved, Jupytext pairing will overwrite the Dendron-compatible frontmatter within the markdown file.\n- Despite this, Dendron Doctor: fixFrontMatter appears to be able to retain the note ID.\n","n":0.088}}},{"i":52,"$":{"0":{"v":"Diagrams","n":1},"1":{"v":"\nDiagramming can be a useful way to illustrate ideas for yourself or others. Sharing a few tools to this effect below (in no particular order).\n\n## Code-based\n\nGenerate diagrams using coded dialects.\n\n- [PlantUML](https://plantuml.com/)\n- [Mermaid](https://mermaid-js.github.io/mermaid/#/)\n- [yUML](https://github.com/jaime-olivares/yuml-diagram/wiki)\n\n## Free-form\n\nFree form tools which allow for \"pen and paper / drag and drop\" style diagrams.\n\n- [Excalidraw](https://excalidraw.com/)\n- [Diagrams.net](https://www.diagrams.net/)\n- [BPMN.io](https://demo.bpmn.io/)\n\n## Aggregate/Mixed\n\nPlatforms which allow for multiple types of diagrams.\n\n- [Kroki](https://kroki.io/)\n","n":0.129}}},{"i":53,"$":{"0":{"v":"Mermaid","n":1}}},{"i":54,"$":{"0":{"v":"Mermaid Style Workarounds","n":0.577},"1":{"v":"\n## Summary\n\nThis page outlines visual styling workarounds with Mermaid.\n\n## Flowchart Font Size\n\nChange the font size of Flowchart content. Note that the Mermaid client or other renderings may not strictly obey the changed font-sizes, sometimes resulting in unchanged image exports.\n\n_Original (small font)_\n\n```mermaid\nflowchart LR\n    subgraph sub_graph1[Subgraph]\n        direction LR\n        Start --> Stop\n    end\n```\n\n_Updated with Font Size Adjusted_\n\n```mermaid\nflowchart LR\n    subgraph sub_graph1[<font size=5>Subgraph]\n        direction LR\n        Start[<font size=5>Start] --> Stop[<font size=5>Stop]\n    end\n```\n\n## Flowchart Subgraph Padding or Margin\n\nAdd padding or margin within subgraphs for readability or design aesthetic improvements.\n\n_Original (subgraph readability challenges)_\n\n```mermaid\nflowchart LR\n    subgraph sub_graph1[Subgraph]\n        direction LR\n        subgraph sub_graph2[A]\n            Start --> Stop\n        end\n        subgraph sub_graph3[B]\n            Outlier --> Stop\n        end\n    end\n```\n\n_Updated with Padding or Margin Added_\n\n```mermaid\nflowchart LR\n    subgraph sub_graph1[Subgraph]\n        subgraph subgraph_padding1[ ]\n            direction LR\n            subgraph sub_graph2[A]\n                Start --> Stop\n            end\n            subgraph sub_graph3[B]\n                Outlier --> Stop\n            end\n        end\n    end\n\nclassDef subgraph_padding fill:none,stroke:none;\nclass subgraph_padding1 subgraph_padding\n```\n","n":0.086}}},{"i":55,"$":{"0":{"v":"Data Visualization","n":0.707},"1":{"v":"\nCovering data visualization tools along with some notes. Items are provided in no particular order.\n\n## Visualization Dashboarding or Platform Tools\n\n- [Microsoft Power BI](https://powerbi.microsoft.com/en-us/)\n  - Windows-only desktop environment.\n  - Access provided via Microsoft account license.\n- [Salesforce Tableau](https://www.tableau.com/)\n  - Access provided to CU users via UIS: <https://www.cu.edu/uis/service-catalog/tableau>\n  - Note distinction between desktop and server, server: private vs public access.\n  - Desktop client typically used to create data sources used by server dashboards.\n- [Google Looker Studio](https://developers.google.com/looker-studio)\n  - Browser-based tool for creating reports and dashboards.\n- [Google Charts](https://developers.google.com/chart/)\n- [Apache Superset](https://superset.apache.org/)\n\n## Visualization Libraries\n\nLibraries used to create visualizations.\n\n- [D3.js](https://d3js.org/)\n- [Vega](https://vega.github.io/vega/)\n- [Matplotlib](https://matplotlib.org/)\n- [Seaborn](https://seaborn.pydata.org/)\n- [Plotly](https://plotly.com/)\n- [Bokeh](https://bokeh.org/)\n\n## Graph or Network Visualization\n\nTools dedicated to graph or network visualization.\n\n- [Gephi](https://gephi.org/)\n- [Netwulf](https://netwulf.readthedocs.io/en/latest/)\n- [NetworkX](https://networkx.org/)\n- [Graphviz](https://graphviz.org/)\n","n":0.095}}},{"i":56,"$":{"0":{"v":"Tableau and Power BI Comparison","n":0.447},"1":{"v":"\nComparisons between Salesforce Tableau and Microsoft Power BI as data visualization tools.\n\n## Key Questions\n\nThere are several key questions to consider when making decisions around data visualization tools. Keep these in mind with the following comparisons and references.\n\n- How are existing skillsets in alignment with the selected tools?\n- What skillsets are desired in future workforce resources?\n- What internal communities are already making use of the selected tools?\n- How do data sources align with visualization tool support? (Layers between data sources and tools may add otherwise hidden complexity and time costs.)\n\n## Feature Comparisons\n\n| Feature | Power BI  | Tableau  |\n| --- | --- | --- |\n| Vendor Support |✅ [ref](https://powerbi.microsoft.com/en-us/support/pro/)  | ✅ [ref](https://www.cu.edu/uis/service-catalog/tableau/support) |\n| CU System Support | ❌  | ✅ [ref](https://www.cu.edu/uis/service-catalog/tableau/support)|\n| Windows Compatibility (Desktop) | ✅ [ref](https://www.microsoft.com/en-us/download/details.aspx?id=58494) | ✅ [ref](https://www.tableau.com/products/techspecs)|\n| MacOS Compatibility (Desktop) | ❌ [ref](https://www.microsoft.com/en-us/download/details.aspx?id=58494) | ✅ [ref](https://www.tableau.com/products/techspecs) |\n\n## Pricing\n\nThe following are public-facing pricing details.\n__Enterprise-based pricing may differ__.\n\n- Power BI: <https://powerbi.microsoft.com/en-us/pricing/>\n- Tableau: <https://www.tableau.com/pricing/teams-orgs>\n\n## Data Sources\n\nData sources which may be connected to the tools.\n\n- Power BI: <https://learn.microsoft.com/en-us/power-bi/connect-data/power-bi-data-sources>\n- Tableau: <https://help.tableau.com/current/pro/desktop/en-us/exampleconnections_overview.htm>\n\n## Visualization Type Support\n\nVisualization types which are supported by the tools.\n\n- Power BI: <https://learn.microsoft.com/en-us/power-bi/visuals/power-bi-visualization-types-for-reports-and-q-and-a>\n- Tableau: <https://help.tableau.com/current/pro/desktop/en-us/what_chart_example.htm>\n\n## Programming Languages\n\nData visualization tools often include their own programming languages which help to specify detailed work which may be necessary beyond drag-and-drop defaults.\n\n- Tableau Level of Detail (LOD): <https://help.tableau.com/current/pro/desktop/en-us/calculations_calculatedfields_lod.htm>\n- Power BI Data Analysis Expressions (DAX): <https://learn.microsoft.com/en-us/dax/>\n\n## Further Reading\n\n- [Tableau.com | Compare Tableau to Microsoft Power BI](https://www.tableau.com/compare/tableau-power-bi)\n\n## Other Alternatives\n\n- Google Looker Studio: <https://lookerstudio.google.com/overview>\nAn all-online data visualization suite which integrates with Google and many other sources.\n- Apache Superset: <https://superset.apache.org/>\nAn open-source data visualization tool supported by the Apache Software Foundation.\n","n":0.062}}},{"i":57,"$":{"0":{"v":"Apps","n":1}}},{"i":58,"$":{"0":{"v":"Mondaydotcom","n":1},"1":{"v":"\n[Monday.com](https://monday.com) is the tool we use for tracking tasks and capturing effort hours. Once a month, tasks are \"posted\" to [[Smartsheet|apps.Smartsheet#^w7ccyzh70hn9]] for later reporting.\n\nAs of this date, their API is not sufficiently rich enough to support using it as the reporting system of record, thus the use of Smartsheet.\n","n":0.143}}},{"i":59,"$":{"0":{"v":"Sketch","n":1}}},{"i":60,"$":{"0":{"v":"Work Visibility Reports","n":0.577},"1":{"v":"\n## Background\n\n```mermaid\nsequenceDiagram\n    Developers->>Management: Raw work visibility\n    Management-->>Developers: Work feedback\n    Management->>Administration: Aggregate work visibility\n    Administration-->>Management: Work feedback\n```\n\n_General sequence of work visibility._\n\nThis document intends to cover solution(s) for work visibility related to the Center for Health AI's (CHAI) projects and internal initiatives. Monday.com is used as a project tracking source, Github is used as the primary source control vehicle. Project work may come in the form of internal continuous improvements, grant-related projects, or other needs CU Anschutz School of Medicine may have.\n\n## Challenge\n\nMonday.com is used as the primary means of work accounting and collaborations but is limited in it's ability to provide administrative visibility. This leads to manual work in creating reports, visualizations, and communications to others where an otherwise automatic solution could be used.\n\n## Porposed Solution(s)\n\n- Each arrow in the diagrams below is roughly equivalent to one \"workflow\" or ETL job which is either triggered or scheduled on a regular basis as needed.\n- \"Datastore\" as seen in the diagrams may be well-suited for object storage with query engine layered above it for utility in downstream deliveries.\n\n### Proposed Flow 1\n\n```mermaid\nflowchart LR\n    monday[Monday.com\\nRaw Data] --> report[Aggregate\\nReport]\n    subgraph Generate\n        report --> storage[Datastore]\n    end\n    subgraph Deliver\n        storage --> PDF\n        PDF --> email\n        storage --> Slack[Slack Channel Post]\n        storage --> Teams[Teams Channel Post]\n    end\n```\n\n_Assumes data is usable or is not needed for archival from Monday.com source._\n\n- Report is generated from raw data and store in CHAI datastore.\n- Report is then sent as Slack, MS Teams posts.\n- Report is also stored in a PDF and sent in an email.\n\n### Proposed Flow 2\n\n```mermaid\nflowchart LR\n    monday[Monday.com\\nRaw Data] --> storage[Datastore]\n    subgraph Generate\n        storage --> report[Aggregate\\nReport]\n        report --> storage\n    end\n    subgraph Deliver\n        storage --> PDF\n        PDF --> email\n        storage --> Slack[Slack Channel Post]\n        storage --> Teams[Teams Channel Post]\n    end\n```\n\n_Assumes data is not usable or is needed for archival from Monday.com source._\n\n- Monday.com raw data is stored in CHAI datastore.\n- Report is generated from raw data and store in CHAI datastore.\n- Report is then sent as Slack, MS Teams posts.\n- Report is also stored in a PDF and sent in an email.\n","n":0.054}}},{"i":61,"$":{"0":{"v":"Smartsheet","n":1},"1":{"v":"\n[Smartsheet](https://www.smartsheet.com/) is a hosted spreadsheet tool we use for administration and operations. ^w7ccyzh70hn9\n\nOur specific use is centered around reporting effort hours and creating monthly pubmed citation reports.\n","n":0.192}}},{"i":62,"$":{"0":{"v":"Admin","n":1}}},{"i":63,"$":{"0":{"v":"Organization","n":1}}},{"i":64,"$":{"0":{"v":"Organizational Charts and People","n":0.5},"1":{"v":"\n## Summary\n\nThis page outlines where to reference organizational charts or personnel information to better understand hierarchies in context to Software Engineering work.\n\n## University of Colorado Anschutz\n\n### Office of Information Technology\n\n- <https://www.ucdenver.edu/offices/office-of-information-technology/about-oit/oit-leadership>\n\n### School of Medicine\n\n#### Administration\n\n- <https://medschool.cuanschutz.edu/deans-office/leadership/organizational-charts>\n\n#### Information Services\n\n- <https://medschool.cuanschutz.edu/informationservices/our-team>\n\n#### Department of Biomedical Informatics\n\n- <https://medschool.cuanschutz.edu/dbmi/about-us>\n\n## University of Colorado Boulder\n\n### Research & Innovation Office\n\n- See \"Organizational Chart\" on the following page: <https://www.colorado.edu/researchinnovation/about>\n\n### Research Computing\n\n- See \"OIT Organizational Chart\" Link on the following page: <https://oit.colorado.edu/about-oit/our-organization>\n\n## University of Colorado System - UIS\n\n- <https://www.cu.edu/docs/uis-org-chart>\n","n":0.113}}},{"i":65,"$":{"0":{"v":"Onboading","n":1}}},{"i":66,"$":{"0":{"v":"Checklist","n":1},"1":{"v":"## Software Engineering Team Onboarding Checklist\n\n### Summary\n\nThis page is intended for use during onboarding procedures as a living reference of various items and access required by new or existing employees. ^pstts4z91zvt\n\n### Getting Started\n\n- [ ] Profile Headshot Picture\n- [ ] Professional Bio (3-5 sentences)\n- [ ] Team Introduction\n\n### Required Forms and Payroll\n\n- [ ] COVID Vaccination Status Form\n- [ ] Remote Work Agreement Form\n- [ ] Payroll Direct Deposit\n- [ ] IRS W-4\n- [ ] I9 Verification (Correspondence through email)\n- [ ] [PeopleSoft - My Leave](https://www.cu.edu/employee-services/payroll/self-service/my-leave)\n\n### Benefits / Time Off\n\n- [ ] Benefits Enrollment / Benefits Orientation\n- [ ] [Tuition Assistance Benefit for Employees](https://www.cu.edu/employee-services/benefits-wellness/current-employee/tuition-assistance/tuition-assistance-benefit)\n- [ ] [CU on Coursera](https://www.cu.edu/employee-services/professional-growth-training/learning/cu-coursera)\n- [ ] Vacation / Sick Time Accruals\n- [ ] [Holidays](https://www.cu.edu/employee-services/holidays)\n\n### Commuting\n\n- [ ] [Campus and Building Locations](https://www.cuanschutz.edu/about/cu-anschutz-map)\n- [ ] [RTD EcoPass Information](https://www.cuanschutz.edu/offices/facilities-management/parking-transportation-maps/parking/rtd-eco-pass)\n- [ ] [Car Parking Information](https://www.cuanschutz.edu/offices/facilities-management/parking-transportation-maps/parking/permit-parking)\n- [ ] [Bike Parking Information](https://www.cuanschutz.edu/offices/facilities-management/parking-transportation-maps/parking/bikes-and-scooters)\n\n### Training & Certification\n\n- [ ] Canvas - New Employee Orientation (NEO) Course\n- [ ] Skillsoft - CU: HIPAA Regulations (_scorm12_cu_a00020_0001)\n- [ ] Skillsoft - CU: Administrative Analysis Environment (A2E) Basics (_scorm12_cu_u00202_0001)\n- [ ] [Live – Health Data Compass Orientation](https://www.healthdatacompass.org/data-delivery-services/compass-orientation)\n- [ ] [Coursera - Researcher Management Leadership Training](https://www.coursera.org/learn/researcher-management-leadership-training/) (recommended for those new to academic research)\n\n### General Access\n\n- [ ] Claiming Your Account\n- [ ] Email Address\n- [ ] Phone Communication\n- [ ] Duo Enrollment and Activation\n- [ ] LastPass\n- [ ] Google Workspace Account\n- [ ] Google Project(s) Access\n- [ ] [VPN setup](https://www.ucdenver.edu/offices/office-of-information-technology/software/how-do-i-use/vpn-and-remote-access)\n- [ ] Microsoft Teams DBMI Team Access\n- [ ] Slack DBMI Workspace Access\n- [ ] Discord (Suggested Setup for Various Labs/etc.)\n- [ ] Github Account (New or Linked)\n- [ ] Github Org for Center for Health AI\n- [ ] Github Org Team Access\n- [ ] Monday.com\n- [ ] Zoom Account\n- [ ] [Zoom Outlook Add-in](https://support.zoom.us/hc/en-us/articles/115005223126-Installing-the-Zoom-for-Outlook-add-in#h_e4f98edd-27ea-4f6b-a993-bdc5b8cc7d04)\n- [ ] University Badging\n- [ ] [Smartsheets Access (Unlicensed)](https://medschool.zendesk.com/hc/en-us/articles/1500003375301-Creating-an-Unlicensed-user-account)\n- [ ] [[Email Signature Guidance | admin.email-signature]]\n- [ ] Microsoft Profile Image\n- [ ] Slack Profile Image\n- [ ] Zoom Profile Image\n- [ ] [On-campus Room Scheduling](https://schedule.ucdenver.edu/EmsWebApp/)\n- [ ] Departmental Rooms for On-campus Room Scheduling Access\n- [ ] Departmental Policy/Travel/etc. Sharepoint Documentation\n- [ ] [On-campus Wi-fi](https://www.ucdenver.edu/offices/office-of-information-technology/services/internet-and-phones/wireless-and-connectivity)\n\n### Informational\n\n- [ ] Performance Planning and Reviews\n- [ ] Organization Chart\n- [ ] HR Business Partners\n- [ ] Branding Guidelines\n- [ ] School of Medicine (SOM) Information Services\n- [ ] CU Denver & Anschutz Office of Information Technology (OIT)\n- [ ] SOM Teams for Awareness\n- [ ] Purchasing Process\n- [ ] [[Research Lifecycle | resources.model.research-lifecycle]]\n- [ ] Grants\n- [ ] Task Sizing and Timing\n- [ ] Principal Investigators (PI's)\n- [ ] Standard Operating Procedures (SOP's)\n- [ ] Data reproducibility\n- [ ] [OIT Status Page](https://cu-anschutz-denver-oit.statuspage.io/)\n- [ ] [OIT Software Page](https://www.ucdenver.edu/offices/office-of-information-technology/software)\n\n### Research Computing Resources\n\n- [ ] [CU Boulder Research Computing](https://colorado.edu/rc/resources)\n- [ ] [RMACC](https://rmacc.org/)\n- [ ] Supercomputers\n- [ ] PetaLibrary\n- [ ] Globus\n- [ ] [School of Medicine Research Resources Page](https://som.ucdenver.edu/researchresources)\n\n### Team Policies / Cadence / Schedule\n\n- [ ] Vacation / Sick Time Procedures\n- [ ] [Academic Calendar](https://www.cuanschutz.edu/registrar/academic-calendars)\n- [ ] [CU Anschutz Event Calendar](https://calendar.cuanschutz.edu/)\n- [ ] Communication\n- [ ] Seminar, Chalk Talk, Lunch+Learn Attendance\n- [ ] Generalized Source Control Cadence\n- [ ] Project Management Reporting\n- [ ] Weekly Team Meetings\n\n### Data Governance\n\n- [ ] HIPAA Data\n- [ ] FERPA Data\n- [ ] Data Source Approvals\n- [ ] Common CU Data Sources\n","n":0.043}}},{"i":67,"$":{"0":{"v":"Email Signature","n":0.707},"1":{"v":"\nEmail signatures are standardized within the department. Use the following Word document reference point (logging in with your CU credentials), copy the content (including images with links) and modify it to match your personal information where appropriate.\n\n[Email Signature Block Instructions](https://olucdenver.sharepoint.com/:w:/s/CenterforHealthAI939-SoftwareEngineering/EXsfKEe9-HBKtLROR-PWAp4BEc0Ij_nQUDegPIG8ej94sQ?e=zV0PYh)\n","n":0.158}}}]}
